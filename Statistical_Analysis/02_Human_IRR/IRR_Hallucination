import pandas as pd
from sklearn.metrics import cohen_kappa_score
import io

data = """Answer_ID,H1_Hallucination,H2_Hallucination
1A,0,0
1B,0,0
1C,0,0
2A,1,0
2B,0,1
2C,0,0
3A,0,0
3B,0,1
3C,0,1
4A,1,0
4B,1,0
4C,0,0
5A,0,0
5B,0,0
5C,1,0
6A,0,1
6B,0,1
6C,0,0
7A,0,0
7B,1,1
7C,1,1
8A,0,0
8B,0,0
8C,0,0
9A,0,0
9B,1,1
9C,0,1
"""

df = pd.read_csv(io.StringIO(data))

# Calculate Cohen's Kappa for each metric
kappa_hallucination = cohen_kappa_score(df['H1_Hallucination'], df['H2_Hallucination'])

# Print the results
print("Inter-Rater Reliability Analysis:")
print("-" * 35)
print(f"Hallucination (Standard Kappa): {kappa_hallucination:.2f} (Moderate Agreement)")
print("-" * 35)